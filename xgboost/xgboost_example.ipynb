{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e92cb4",
   "metadata": {},
   "source": [
    "## An example of how to run XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df4016",
   "metadata": {},
   "source": [
    "### Step1. Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ff53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install\n",
    "#!pip install xgboost\n",
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75154448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder          \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# import packages for hyperparameters tuning\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed41675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ab443",
   "metadata": {},
   "source": [
    "### Step2. Read data and do pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "023aef65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "data = pd.read_csv(url)\n",
    "#Find how many rows and columns\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f71a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Summary of dataset \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e8ed64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ada842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with too many missing values\n",
    "data.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "257f552e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Embarked  \n",
       "0      0         A/5 21171   7.2500        S  \n",
       "1      0          PC 17599  71.2833        C  \n",
       "2      0  STON/O2. 3101282   7.9250        S  \n",
       "3      0            113803  53.1000        S  \n",
       "4      0            373450   8.0500        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "438d3306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Embarked  \n",
       "0         A/5 21171   7.2500        S  \n",
       "1          PC 17599  71.2833        C  \n",
       "2  STON/O2. 3101282   7.9250        S  \n",
       "3            113803  53.1000        S  \n",
       "4            373450   8.0500        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfrom attribute\n",
    "le = LabelEncoder()\n",
    "data['Sex'] = le.fit_transform(data['Sex'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591c901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd133be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide variables to use\n",
    "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "y = data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f0c169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3838f5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 6), (179, 6))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/test split (80/20)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=65)\n",
    "x_train.shape , x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d87a86",
   "metadata": {},
   "source": [
    "### Step4. Run XGBoost with Hyperparameter tunining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3880f89e",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization implementation \n",
    "To build more robust models with XGBoost, we should always perform k-fold cross validation.\n",
    "- booster[default = gbtree]\n",
    "- eta [default=0.3, alias: learning_rate]\n",
    "- gamma [default=0, alias: min_split_loss]\n",
    "- max_depth [default=6]\n",
    "- min_child_weight [default=1]\n",
    "- max_delta_step [default=0]\n",
    "- subsample [default=1]\n",
    "- colsample_bytree, colsample_bylevel, colsample_bynode [default=1]\n",
    "- lambda [default=1, alias: reg_lambda]\n",
    "- alpha [default=0, alias: reg_alpha]\n",
    "- scale_pos_weight [default=1]\n",
    "\n",
    "- HYPEROPT is a powerful python library that search through an hyperparameter space of values and find the best possible values that yield the minimum of the loss function.\n",
    "\n",
    "- Bayesian Optimization technique uses Hyperopt to tune the model hyperparameters. Hyperopt is a Python library which is used to tune model hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "627b6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 180,\n",
    "        'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc246bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier(use_label_encoder=False,\n",
    "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( x_train, y_train), ( x_test, y_test)]\n",
    "    \n",
    "    clf.fit(x_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"logloss\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed405659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.770949720670391                                                               \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.770949720670391                                                               \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.8044692737430168                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.8044692737430168                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.8044692737430168                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.8212290502793296                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.7988826815642458                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.770949720670391                                                               \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.770949720670391                                                               \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.8212290502793296                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877094972067039                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.7486033519553073                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.770949720670391                                                               \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.8044692737430168                                                              \n",
      "SCORE:                                                                          \n",
      "0.8044692737430168                                                              \n",
      "SCORE:                                                                          \n",
      "0.7988826815642458                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.8044692737430168                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.8044692737430168                                                              \n",
      "SCORE:                                                                          \n",
      "0.7988826815642458                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.8044692737430168                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.8044692737430168                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.8044692737430168                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.8212290502793296                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.7877094972067039                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.7486033519553073                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.7430167597765364                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "SCORE:                                                                          \n",
      "0.6368715083798883                                                              \n",
      "100%|██████| 100/100 [00:07<00:00, 13.47trial/s, best loss: -0.8212290502793296]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421c576",
   "metadata": {},
   "source": [
    "- Here best_hyperparams gives us the optimal parameters that best fit model and better loss function value.\n",
    "\n",
    "- trials is an object that contains or stores all the relevant information such as hyperparameter, loss-functions for each set of parameters that the model has been trained.\n",
    "\n",
    "- ‘fmin’ is an optimization function that minimizes the loss function and takes in 4 inputs - fn, space, algo and max_evals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce0a84c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters are :  \n",
      "\n",
      "{'colsample_bytree': 0.5370349918217041, 'gamma': 5.608870758199104, 'max_depth': 15.0, 'min_child_weight': 7.0, 'reg_alpha': 48.0, 'reg_lambda': 0.3036158352299454}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb4c2b1",
   "metadata": {},
   "source": [
    "### Step6. Run XGBoost with the tuned parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "150a8d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5370349918217041,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              gamma=5.608870758199104, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=15, min_child_weight=7.0, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=48.0, reg_lambda=0.3036158352299454, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declare parameters\n",
    "params = {\n",
    "            'objective':'binary:logistic',\n",
    "            'n_estimators':100,\n",
    "            'eval_metric':'logloss',\n",
    "            'use_label_encoder':False\n",
    "        }         \n",
    "params.update(best_hyperparams)\n",
    "\n",
    "# changing datatypes for integer hyper parameters\n",
    "int_hp = [\"max_depth\"]\n",
    "for h in int_hp:\n",
    "    params[h] = int(params[h])\n",
    "\n",
    "# instantiate the classifier \n",
    "xgb_best = xgb.XGBClassifier(**params)\n",
    "\n",
    "\n",
    "# fit the classifier to the training data\n",
    "xgb_best.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a345bc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.5370349918217041,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              gamma=5.608870758199104, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=15, min_child_weight=7.0, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=48.0, reg_lambda=0.3036158352299454, scale_pos_weight=1,\n",
      "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# we can view the parameters of the xgb trained model as follows -\n",
    "\n",
    "print(xgb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56c53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46d3c46c",
   "metadata": {},
   "source": [
    "### Step6. Make predictions with XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d23968aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on test data\n",
    "y_pred = xgb_best.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812276a8",
   "metadata": {},
   "source": [
    "### Step7. Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61bf4ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model accuracy score: 0.7989\n"
     ]
    }
   ],
   "source": [
    "# compute and print accuracy score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2779a00",
   "metadata": {},
   "source": [
    "### Step8. Feature importance with XGBoost\n",
    "XGBoost provides a way to examine the importance of each feature in the original dataset within the model.\n",
    "It involves counting the number of times each feature is split on across all boosting trees in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bb5c0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(xgb_best)\n",
    "plt.figure(figsize = (16, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cd12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ea80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da1ea51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141b222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
